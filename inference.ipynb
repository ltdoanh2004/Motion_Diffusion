{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5446ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MotionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c784bad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltdoanh/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder = MotionTransformer(\n",
    "        input_feats=264,\n",
    "        num_frames=360,\n",
    "        num_layers=8,\n",
    "        latent_dim=512,\n",
    "        no_clip=False,\n",
    "        no_eff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d965f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.get_opt import get_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51d878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./checkpoints/beat/beat_diffusion_v1/opt.txt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "opt_path = \"./checkpoints/beat/beat_diffusion_v1/opt.txt\"\n",
    "opt = get_opt(opt_path, device)\n",
    "opt.do_denoise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66782169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 62.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 264)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "from trainers import DDPMTrainer\n",
    "\n",
    "mean = np.load(pjoin(opt.meta_dir, 'mean.npy'))\n",
    "std = np.load(pjoin(opt.meta_dir, 'std.npy'))\n",
    "trainer = DDPMTrainer(opt, encoder)\n",
    "trainer.load(pjoin(opt.model_dir, opt.which_epoch + '.tar'))\n",
    "\n",
    "trainer.eval_mode()\n",
    "trainer.to(opt.device)\n",
    "\n",
    "result_dict = {}\n",
    "with torch.no_grad():\n",
    "        caption = [\"hi how are u\"]\n",
    "        m_lens = torch.LongTensor([360]).to(device)\n",
    "        pred_motions = trainer.generate(caption, m_lens, 264)\n",
    "        motion = pred_motions[0].cpu().numpy()\n",
    "        print(motion.shape)\n",
    "opt.result_dir = \"/home/ltdoanh/ldtan/Motion_Diffusion/checkpoints\"\n",
    "np.save(pjoin(opt.result_dir, 'motion.npy'), motion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
